An√°lise Cr√≠tica e Diagn√≥stico
Primeiro, a observa√ß√£o mais importante:
O prompt que voc√™ criou √© excelente, mas ele N√ÉO √© um prompt RAG. Ele √© um System Prompt (ou Prompt de Sistema / Instru√ß√µes Base). E essa distin√ß√£o √© fundamental.
System Prompt (O que voc√™ criou): Define a personalidade, as regras de comportamento e as grades de seguran√ßa (guardrails) do assistente. √â o "DNA" ou a "constitui√ß√£o" dele. Ele governa todas as respostas, independentemente da tarefa. As regras como "n√£o use JSON", "transfira se o cliente pedir" e "n√£o invente dados" s√£o perfeitas para isso.
Prompt RAG (O que precisamos criar/refinar): √â um prompt espec√≠fico para a tarefa de responder com base em contexto recuperado. Ele √© usado no momento da consulta e instrui o modelo sobre como usar os trechos de texto que foram recuperados do Upstash Vector para responder √† pergunta do usu√°rio.
Conclus√£o do Diagn√≥stico: Voc√™ j√° tem um System Prompt de alta qualidade. Agora, precisamos criar um prompt RAG igualmente bom e garantir que eles trabalhem juntos.
Onde o seu "System Prompt" deve viver?
Ele deve ser a base das instructions de cada um dos seus Assistentes na OpenAI. Por exemplo, as instru√ß√µes do LIA Suporte come√ßariam exatamente com essas regras.
code
Code
# Instructions para o Assistant "LIA Suporte" na OpenAI

## REGRAS ABSOLUTAS - NUNCA VIOLAR
**1. NUNCA retorne JSON nas respostas ao cliente**
   - Sempre responda em linguagem natural
   - JSON √© apenas para comunica√ß√£o interna
**2. SEMPRE use transferir_para_humano quando cliente pedir**
   - Sem exce√ß√£o
   - Imediatamente
   - N√£o tente convencer a continuar com IA
... (todas as suas outras regras) ...

---

## Persona e Objetivos do LIA Suporte
Voc√™ √© a LIA, uma especialista em suporte t√©cnico da TR Telecom. Seu objetivo √© diagnosticar e resolver problemas de conex√£o de forma clara e paciente...
Como Melhorar o Contexto com um Verdadeiro Prompt RAG
Agora, vamos criar o prompt que ser√° usado quando a function consultar_base_de_conhecimento for chamada e retornar um contexto. Este prompt √© constru√≠do dinamicamente, em tempo de execu√ß√£o.
O objetivo dele √© for√ßar o modelo a se basear exclusivamente nos fatos recuperados, evitando alucina√ß√µes e garantindo que a resposta venha da sua base de conhecimento.
Modelo de Prompt RAG (para ser usado no LIA CORTEX)
code
Code
--- CONTEXTO DA BASE DE CONHECIMENTO ---
{contexto_recuperado_do_upstash}

--- HIST√ìRICO RECENTE DO CHAT ---
{historico_da_conversa}

--- PERGUNTA DO USU√ÅRIO ---
{pergunta_do_usuario}

--- SUA TAREFA ---
1.  **Analise a PERGUNTA DO USU√ÅRIO** usando o HIST√ìRICO DO CHAT para entender o que est√° sendo pedido.
2.  **Formule uma resposta precisa e concisa usando APENAS as informa√ß√µes contidas no CONTEXTO DA BASE DE CONHECIMENTO.**
3.  **Se a resposta para a PERGUNTA n√£o estiver no CONTEXTO fornecido, responda de forma clara e honesta:** "N√£o encontrei essa informa√ß√£o espec√≠fica na minha base de conhecimento. Posso tentar te ajudar de outra forma?"
4.  **NUNCA** mencione a exist√™ncia da "base de conhecimento" ou do "contexto" na sua resposta. Aja como se voc√™ soubesse a informa√ß√£o naturalmente.
5.  Responda seguindo todas as regras absolutas e de persona definidas para voc√™.
Por que este prompt RAG √© eficaz?
Estrutura Clara (---): Separa inequivocamente as diferentes fontes de informa√ß√£o para o modelo (contexto factual, hist√≥rico da conversa e a tarefa a ser executada).
Grounded Generation (Regra 3): A regra mais importante de um sistema RAG. Ela instrui o modelo sobre o que fazer quando a informa√ß√£o n√£o est√° dispon√≠vel. Isso combate diretamente a alucina√ß√£o e aumenta a confian√ßa no sistema.
Foco Exclusivo no Contexto (Regra 2): A instru√ß√£o "usando APENAS as informa√ß√µes contidas no CONTEXTO" for√ßa o modelo a priorizar os dados que voc√™ forneceu em vez de seu conhecimento de treinamento geral.
Experi√™ncia do Usu√°rio Fluida (Regra 4): Evita que a IA pare√ßa um rob√¥ que est√° "lendo um manual". A resposta deve parecer natural, escondendo a mec√¢nica do RAG do cliente final.
Integra√ß√£o com as Regras Gerais (Regra 5): Garante que, mesmo ao executar a tarefa RAG, a IA ainda respeite o System Prompt original (mensagens curtas, uso de emojis, etc.).
Fluxo Unificado: Como Tudo Funciona Junto
O LIA Suporte tem o seu System Prompt configurado nas suas instructions na OpenAI.
Um cliente pergunta: "Qual a taxa de upload do plano Fibra Gamer?"
O assistente determina que precisa de informa√ß√£o e chama a function: consultar_base_de_conhecimento(query: "taxa de upload plano Fibra Gamer").
O LIA CORTEX executa a busca no Upstash e obt√©m o seguinte texto: [Contexto Recuperado] "O plano Fibra Gamer oferece 1 Gbit/s de download e 500 Mbit/s de upload. √â otimizado para baixa lat√™ncia..."
Agora, o LIA CORTEX monta o Prompt RAG final e o envia de volta para a OpenAI para que o assistente formule a resposta.
O assistente recebe tanto as suas instru√ß√µes permanentes (o System Prompt) quanto a tarefa espec√≠fica (o Prompt RAG) e gera a resposta final, seguindo todas as regras:
"O plano Fibra Gamer conta com uma taxa de upload de 500 Mbit/s! √â ideal para streaming e jogos online. üòâ"