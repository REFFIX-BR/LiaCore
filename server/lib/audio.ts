import OpenAI from "openai";
import { webhookLogger } from "./webhook-logger";
import { trackTokenUsage } from "./openai-usage";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

/**
 * Transcreve √°udio usando Whisper API da OpenAI
 * 
 * @param audioBase64 - √Åudio em base64 (sem prefixo data:audio/...)
 * @param mimeType - Tipo MIME do √°udio (audio/mpeg, audio/ogg, audio/wav, etc.)
 * @returns Transcri√ß√£o do √°udio ou null se falhar
 */
export async function transcribeAudio(
  audioBase64: string,
  mimeType: string = "audio/mpeg"
): Promise<string | null> {
  try {
    // Converter base64 para Buffer
    const audioBuffer = Buffer.from(audioBase64, "base64");
    
    // Determinar extens√£o do arquivo baseado no MIME type
    const extensionMap: Record<string, string> = {
      "audio/mpeg": "mp3",
      "audio/mp3": "mp3",
      "audio/ogg": "ogg",
      "audio/wav": "wav",
      "audio/webm": "webm",
      "audio/mp4": "mp4",
      "audio/m4a": "m4a",
    };
    
    const extension = extensionMap[mimeType.toLowerCase()] || "mp3";
    
    // Criar um File-like object para a API
    const audioFile = new File([audioBuffer], `audio.${extension}`, {
      type: mimeType,
    });

    console.log(`üé§ [Audio] Iniciando transcri√ß√£o de √°udio (${(audioBuffer.length / 1024).toFixed(2)}KB, ${extension})`);

    // Chamar Whisper API para transcri√ß√£o
    const transcription = await openai.audio.transcriptions.create({
      file: audioFile,
      model: "whisper-1",
      language: "pt", // Portugu√™s
      response_format: "text",
    });

    if (!transcription) {
      console.error("‚ùå [Audio] Whisper API retornou resposta vazia");
      webhookLogger.error("AUDIO_TRANSCRIPTION_FAILED", "Whisper retornou vazio", {
        audioSize: audioBuffer.length,
        mimeType,
      });
      return null;
    }

    console.log(`‚úÖ [Audio] Transcri√ß√£o conclu√≠da: ${transcription.substring(0, 100)}...`);
    
    // Estima dura√ß√£o do √°udio em minutos (aproxima√ß√£o: 1MB ‚âà 60 segundos de √°udio)
    const audioSizeKB = audioBuffer.length / 1024;
    const estimatedMinutes = Math.max(0.1, (audioSizeKB / 1024)); // KB/1024 = MB, e 1MB ‚âà 1 minuto de √°udio
    
    // Track usage (Whisper cobra $0.006 por minuto)
    // Armazenamos como "tokens" para aproveitar infraestrutura existente
    // 1 minuto = 1 "token" (ser√° multiplicado pelo pre√ßo correto no c√°lculo)
    const estimatedTokens = Math.ceil(estimatedMinutes);
    await trackTokenUsage("whisper-1", estimatedTokens, 0);
    
    webhookLogger.success("AUDIO_TRANSCRIBED", "√Åudio transcrito com sucesso", {
      audioSize: audioBuffer.length,
      mimeType,
      transcriptionLength: transcription.length,
    });

    return transcription;
  } catch (error) {
    console.error("‚ùå [Audio] Erro ao transcrever √°udio:", error);
    
    webhookLogger.error("AUDIO_TRANSCRIPTION_ERROR", "Erro na transcri√ß√£o", {
      error: error instanceof Error ? error.message : String(error),
      audioSize: audioBase64.length,
      mimeType,
    });

    return null;
  }
}

/**
 * Valida se o formato de √°udio √© suportado
 */
export function isValidAudioFormat(mimeType: string): boolean {
  const supportedFormats = [
    "audio/mpeg",
    "audio/mp3",
    "audio/ogg",
    "audio/wav",
    "audio/webm",
    "audio/mp4",
    "audio/m4a",
  ];
  
  return supportedFormats.includes(mimeType.toLowerCase());
}

/**
 * Valida tamanho do √°udio (m√≠n 1KB, m√°x 25MB para Whisper)
 */
export function isValidAudioSize(audioBase64: string): boolean {
  const audioSizeBytes = (audioBase64.length * 3) / 4;
  const minSizeBytes = 1024; // 1KB (m√≠nimo para ser um √°udio v√°lido)
  const maxSizeBytes = 25 * 1024 * 1024; // 25MB (limite do Whisper)
  return audioSizeBytes >= minSizeBytes && audioSizeBytes <= maxSizeBytes;
}
